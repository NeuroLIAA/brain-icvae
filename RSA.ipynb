{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining and fine-tuning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUCs plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from pathlib import Path\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def load_aucs(base_path, task, filename):\n",
    "    file_path = base_path / task / filename\n",
    "    aucs = read_csv(file_path, index_col=0)\n",
    "    aucs['AUC_data'] = aucs['AUC_data'].dropna().apply(literal_eval)\n",
    "    aucs['PRC_data'] = aucs['PRC_data'].dropna().apply(literal_eval)\n",
    "    return aucs\n",
    "\n",
    "def prepare_violin_data(all_aucs, metric_col):\n",
    "    \"\"\"\n",
    "    Prepare data for violin plots by converting lists to long format\n",
    "    \"\"\"\n",
    "    plot_data = []\n",
    "    \n",
    "    for task in all_aucs.keys():\n",
    "        df = all_aucs[task]\n",
    "        df_clean = df.dropna(subset=[metric_col])\n",
    "        \n",
    "        for model in df_clean.index:\n",
    "            values = df_clean.loc[model, metric_col]\n",
    "            for value in values:\n",
    "                plot_data.append({\n",
    "                    'Task': task,\n",
    "                    'Model': model,\n",
    "                    'Value': value,\n",
    "                })\n",
    "    \n",
    "    return DataFrame(plot_data)\n",
    "\n",
    "def plot_violin_data(data, tasks, metric_name, ax_row, axes, colors, fig=None, add_legend=False):\n",
    "    plt.rcParams['font.family'] = 'Roboto'\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    task_labels = {\n",
    "        'ad_vs_hc': 'AD vs HC',\n",
    "        'ad_vs_mci': 'AD vs MCI', \n",
    "        'mci_vs_hc': 'MCI vs HC'\n",
    "    }\n",
    "    \n",
    "    for col, task in enumerate(tasks):\n",
    "        ax = axes[ax_row, col]\n",
    "        task_data = data[data['Task'] == task]\n",
    "        order = task_data['Model'].unique()\n",
    "        palette = dict(zip(order, colors))\n",
    "\n",
    "        sns.violinplot(data=task_data, x='Model', y='Value', ax=ax)\n",
    "\n",
    "        if ax_row == 0:\n",
    "            ax.set_title(f'{task_labels[task]}', fontsize=12)\n",
    "        if metric_name == 'AUC':\n",
    "            ax.set_ylim(0.5, 1.0)\n",
    "        else:  # PRC\n",
    "            ax.set_ylim(0.4, 1.0)\n",
    "\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f'{metric_name}', fontsize=14)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_yticklabels([])\n",
    "            \n",
    "        bodies = [c for c in ax.collections if isinstance(c, PolyCollection)]\n",
    "        for body, model in zip(bodies, order):\n",
    "            color = palette[model] \n",
    "            body.set_facecolor(color)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.spines['top'].set_color('black')\n",
    "        ax.spines['right'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['top'].set_linewidth(.8)\n",
    "        ax.spines['right'].set_linewidth(.8)\n",
    "        ax.spines['bottom'].set_linewidth(.8)\n",
    "        ax.spines['left'].set_linewidth(.8)\n",
    "\n",
    "    if add_legend and fig is not None:\n",
    "        model_names = ['Age-finetuned', 'Sex-finetuned', 'BMI-finetuned', 'Non-pretrained']\n",
    "        model_patches = [mlines.Line2D([], [], color=colors[i], label=model_names[i], linewidth=2) for i in range(len(model_names))]\n",
    "        legend_elements = model_patches\n",
    "        \n",
    "        fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.525, 0.05), \n",
    "                   ncol=5, fontsize=14, frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDMs plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:03:01.196579Z",
     "start_time": "2025-06-23T15:03:01.186347Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def join_layers(task_rdms, layer, models):\n",
    "    joined_rdms = {}\n",
    "    for model in models:\n",
    "        model_rdms = task_rdms[model]\n",
    "        training_modes = models[model]\n",
    "        for training_mode in training_modes:\n",
    "            training_mode_rdm = model_rdms[training_mode]\n",
    "            if layer not in training_mode_rdm:\n",
    "                continue\n",
    "            joined_rdms[f'{model}_{training_mode}'] = training_mode_rdm[layer]\n",
    "    return joined_rdms\n",
    "\n",
    "\n",
    "def base_name(model_name):\n",
    "    basename = model_name.split('_')[0]\n",
    "    if basename == 'bmi':\n",
    "        return 'BMI'\n",
    "    elif basename == 'baseline':\n",
    "        return 'Voxel Representation'\n",
    "    return basename.capitalize() \n",
    "\n",
    "\n",
    "def plot_model_comparisons(comparisons_dict, model_type, layers='all', x_label='Layers', group_by='layer', legend=True, title=None,\n",
    "                           fig_size=(10, 8), only_baseline=False, colors=None):\n",
    "    models = [key for key in comparisons_dict.keys() if key.endswith(f'_{model_type}')]\n",
    "    if model_type == 'tl' and only_baseline:\n",
    "        models += [f'baseline_{model_type}']\n",
    "        model_pairs = [(model, f'baseline_{model_type}') for model in models if model != f'baseline_{model_type}']\n",
    "    else:\n",
    "        model_pairs = list(combinations(models, 2))\n",
    "    model_pairs = sorted(model_pairs, key=lambda x: ('none' in x[0].lower(), 'none' in x[1].lower(), x[0], x[1]))\n",
    "    \n",
    "    if layers == 'all':\n",
    "        first_comparison = next(iter(comparisons_dict.values()))\n",
    "        first_layer_dict = next(iter(first_comparison.values()))\n",
    "        layers = list(first_layer_dict.keys())\n",
    "    if not isinstance(layers, list):\n",
    "        raise ValueError(\"Layers should be a list of layer names or 'all' to use all available layers.\")\n",
    "    \n",
    "    data_rows = []\n",
    "    for layer in layers:\n",
    "        for model1, model2 in model_pairs:            \n",
    "            if model1 in comparisons_dict and model2 in comparisons_dict[model1]:\n",
    "                correlations = comparisons_dict[model1][model2][layer]\n",
    "            elif model2 in comparisons_dict and model1 in comparisons_dict[model2]:\n",
    "                correlations = comparisons_dict[model2][model1][layer]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            comparison = f\"{base_name(model1)} vs {base_name(model2)}\"\n",
    "            if 'none' in model1.lower() or 'none' in model2.lower():\n",
    "                group = 'non-pretrained'\n",
    "            elif 'baseline' in model1.lower() or 'baseline' in model2.lower():\n",
    "                group = 'voxel model'\n",
    "            else:\n",
    "                group = 'pretrained'\n",
    "            for corr in correlations:\n",
    "                data_rows.append({\n",
    "                    'layer': layer,\n",
    "                    'comparison': comparison,\n",
    "                    'correlation': corr,\n",
    "                    'group': group\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(data_rows)\n",
    "    if colors:\n",
    "        color_map = colors\n",
    "    else:\n",
    "        color_map = sns.color_palette(\"Set2\")\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.rcParams['font.family'] = 'Roboto'\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    \n",
    "    if group_by == 'layer':\n",
    "        x = 'layer'\n",
    "    else:\n",
    "        x = 'group'\n",
    "\n",
    "    ax = sns.violinplot(data=df, x=x, y='correlation', hue='comparison', palette=color_map, legend=legend, cut=0, alpha=1.0,\n",
    "                        density_norm='width', width=0.8, bw_adjust=2)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16)\n",
    "    \n",
    "    min_value = round(df['correlation'].min() - 0.05, 1)\n",
    "    # plt.yticks(list(np.arange(min_value, 1.0, 0.1)) + [1.0], fontsize=10)\n",
    "    # plt.yticks(list(np.arange(0.75, 1.0, 0.1)) + [1.0], fontsize=10)\n",
    "\n",
    "    if legend:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        n_comparisons = len(model_pairs)\n",
    "        ax.legend(handles[:n_comparisons], labels[:n_comparisons], ncol=n_comparisons,\n",
    "                title='Comparisons', loc='lower center', # bbox_to_anchor=(1.05, 1)\n",
    "                )\n",
    "        ax.set_ylim(bottom=0.0)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel('Correlation distance', fontsize=11)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "    ax.spines['top'].set_color('black')\n",
    "    ax.spines['right'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['top'].set_linewidth(.8)\n",
    "    ax.spines['right'].set_linewidth(.8)\n",
    "    ax.spines['bottom'].set_linewidth(.8)\n",
    "    ax.spines['left'].set_linewidth(.8)\n",
    "    if legend:\n",
    "        ax.legend(title='Models')\n",
    "    fig.patch.set_alpha(0.0)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def parse_task_name(task):\n",
    "    if task == 'ad_vs_hc':\n",
    "        return 'AD vs HC'\n",
    "    elif task == 'ad_vs_mci':\n",
    "        return 'AD vs MCI'\n",
    "    elif task == 'mci_vs_hc':\n",
    "        return 'MCI vs HC'\n",
    "    return task\n",
    "\n",
    "def plot_representational_shifts(representational_shifts, legend=False):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['font.family'] = 'Roboto'\n",
    "    models = [m.lower() for m in representational_shifts.keys()]\n",
    "    tasks = list(next(iter(representational_shifts.values())).keys())\n",
    "    colors = sns.color_palette('deep', n_colors=len(models))\n",
    "\n",
    "    # Build long-form DataFrame for seaborn\n",
    "    plot_data = []\n",
    "    for model in models:\n",
    "        model_label = f'{model.capitalize()} finetuned' if model != 'bmi' else 'BMI finetuned'\n",
    "        for task in tasks:\n",
    "            values = representational_shifts[model][task]\n",
    "            for v in values:\n",
    "                plot_data.append({\n",
    "                    'Task': parse_task_name(task),\n",
    "                    'Model': model_label,\n",
    "                    'Value': v,\n",
    "                })\n",
    "    df = pd.DataFrame(plot_data)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    model_labels = [f'{m.capitalize()} finetuned' if m != 'bmi' else 'BMI finetuned' for m in models]\n",
    "    palette = dict(zip(model_labels, colors))\n",
    "\n",
    "    sns.violinplot(data=df, x='Task', y='Value', hue='Model', hue_order=model_labels,\n",
    "                   palette=palette, ax=ax, inner='box', linewidth=0.8, alpha=1.0, cut=0, width=0.5, legend=legend)\n",
    "\n",
    "    ax.set_ylim(bottom=0.0)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Distance to pretrained representation', fontsize=11)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "    ax.spines['top'].set_color('black')\n",
    "    ax.spines['right'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['top'].set_linewidth(.8)\n",
    "    ax.spines['right'].set_linewidth(.8)\n",
    "    ax.spines['bottom'].set_linewidth(.8)\n",
    "    ax.spines['left'].set_linewidth(.8)\n",
    "    if legend:\n",
    "        ax.legend(title='Models')\n",
    "    fig.patch.set_alpha(0.0)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_rsa_histogram_grid(compared_rdms, layer, tasks, only_diagonal=False):\n",
    "    sns.set_theme()\n",
    "    pretrained_color = sns.color_palette()[0]\n",
    "    finetuned_color = sns.color_palette()[1]\n",
    "\n",
    "    if only_diagonal:\n",
    "        first_task_rdms = compared_rdms[tasks[0]]\n",
    "        models = [model for model in first_task_rdms.keys() if 'pretrained' in model]\n",
    "        n_models = len(models)\n",
    "        n_tasks = len(tasks)\n",
    "        fig, axes = plt.subplots(n_models, n_tasks, figsize=(2 * n_tasks, 1.431 * n_models), squeeze=False,\n",
    "                                 sharex=True)\n",
    "\n",
    "        all_values = []\n",
    "        for model in models:\n",
    "            for task in tasks:\n",
    "                task_rdms = compared_rdms[task]\n",
    "                y_pretrained = f\"{model.split('_')[0]}_pretrained\"\n",
    "                y_finetuned = f\"{model.split('_')[0]}_tl\"\n",
    "                all_values.extend(task_rdms[model][y_pretrained][layer])\n",
    "                all_values.extend(task_rdms[model][y_finetuned][layer])\n",
    "        global_min = min(all_values)\n",
    "        global_max = max(all_values)\n",
    "        padding = (global_max - global_min) * 0.05\n",
    "        global_min -= padding\n",
    "        global_max += padding\n",
    "\n",
    "        for row, model in enumerate(models):\n",
    "            model_name = model.split('_')[0].capitalize()\n",
    "            if model_name == 'Bmi': model_name = 'BMI'\n",
    "            for col, task in enumerate(tasks):\n",
    "                ax = axes[row, col]\n",
    "                task_rdms = compared_rdms[task]\n",
    "                y_pretrained = f\"{model.split('_')[0]}_pretrained\"\n",
    "                y_finetuned = f\"{model.split('_')[0]}_tl\"\n",
    "                pretrained_data = task_rdms[model][y_pretrained][layer]\n",
    "                finetuned_data = task_rdms[model][y_finetuned][layer]\n",
    "                ax.axvline(x=1, color=pretrained_color, lw=2, alpha=0.7)\n",
    "                sns.kdeplot(finetuned_data, ax=ax, fill=True, alpha=0.5, color=finetuned_color,\n",
    "                            label=f'vs {y_finetuned}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "                ax.set_xlim(global_min, global_max)\n",
    "                ax.grid(alpha=0.5)\n",
    "                ax.set_yticks([])\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(f'{model_name} pretrained', fontsize=10)\n",
    "                else:\n",
    "                    ax.set_ylabel('')\n",
    "                    ax.set_yticklabels([])\n",
    "                if row == n_models - 1:\n",
    "                    ax.tick_params(axis='x', labelsize=9)\n",
    "                if row == 0:\n",
    "                    parsed_task_title = task.replace('ad_vs_hc', 'AD vs HC').replace('ad_vs_mci', 'AD vs MCI').replace('mci_vs_hc', 'MCI vs HC')\n",
    "                    ax.set_title(parsed_task_title, fontsize=10)\n",
    "                else:\n",
    "                    ax.set_title('')\n",
    "\n",
    "        handles = [\n",
    "            plt.Line2D([0], [0], color=pretrained_color, lw=4, alpha=0.7),\n",
    "            plt.Line2D([0], [0], color=finetuned_color, lw=4, alpha=0.7)\n",
    "        ]\n",
    "        labels = ['Pretrained', 'Fine-tuned']\n",
    "        fig.legend(handles, labels, fontsize=9, frameon=True, loc='lower right', ncol=2, columnspacing=0.8, handlelength=.1)\n",
    "        fig.supxlabel('Correlation value', fontsize=10)\n",
    "        plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95], pad=0)\n",
    "        return fig\n",
    "\n",
    "    if isinstance(tasks, str):\n",
    "        task = tasks\n",
    "    else:\n",
    "        task = tasks[0]\n",
    "    compared_rdms = compared_rdms[task]\n",
    "    x_models = [model for model in compared_rdms.keys() if 'pretrained' in model]\n",
    "    y_model_pairs = [(f'{y_model.split(\"_\")[0]}_pretrained', f'{y_model.split(\"_\")[0]}_tl') for y_model in x_models]\n",
    "\n",
    "    fig, axes = plt.subplots(len(y_model_pairs), len(x_models), figsize=(10, 8))\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    parsed_task_title = task.replace('ad_vs_hc', 'AD and HC')\n",
    "    parsed_task_title = parsed_task_title.replace('ad_vs_mci', 'AD and MCI')\n",
    "    parsed_task_title = parsed_task_title.replace('mci_vs_hc', 'MCI and HC')\n",
    "    fig.suptitle(f'RSA Analysis on {parsed_task_title} subjects for layer {layer}', fontsize=14)\n",
    "\n",
    "    all_values = []\n",
    "    for x_model in x_models:\n",
    "        for y_pretrained, y_finetuned in y_model_pairs:\n",
    "            all_values.extend(compared_rdms[x_model][y_pretrained][layer])\n",
    "            all_values.extend(compared_rdms[x_model][y_finetuned][layer])\n",
    "    global_min = min(all_values)\n",
    "    global_max = max(all_values)\n",
    "    padding = (global_max - global_min) * 0.05\n",
    "    global_min -= padding\n",
    "    global_max += padding\n",
    "\n",
    "    for col, x_model in enumerate(x_models):\n",
    "        model_name = x_model.split('_')[0]\n",
    "        if model_name == 'bmi': model_name = 'BMI'\n",
    "        col_title = f'Similarity to {model_name} prediction model'\n",
    "        axes[0, col].set_title(col_title, fontsize=11)\n",
    "\n",
    "    for row, (pretrained, _) in enumerate(y_model_pairs):\n",
    "        model_name = pretrained.split('_')[0].capitalize()\n",
    "        if model_name == 'Bmi': model_name = 'BMI'\n",
    "        ylabel = f'{model_name} prediction\\n before and after fine-tuning'\n",
    "        axes[row, 0].set_ylabel(ylabel, fontsize=10)\n",
    "\n",
    "    fig.text(0.5, 0.02, 'Correlation value', ha='center', fontsize=14)\n",
    "    fig.text(0.02, 0.5, 'Similarity density', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    for row, (y_pretrained, y_finetuned) in enumerate(y_model_pairs):\n",
    "        for col, x_model in enumerate(x_models):\n",
    "            ax = axes[row, col]\n",
    "            ax.set_yticks([])\n",
    "            if col > 0:\n",
    "                ax.set_yticklabels([])\n",
    "            if row < len(y_model_pairs) - 1:\n",
    "                ax.set_xticks([])\n",
    "            else:\n",
    "                ax.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "            pretrained_data = compared_rdms[x_model][y_pretrained][layer]\n",
    "            finetuned_data = compared_rdms[x_model][y_finetuned][layer]\n",
    "            if row != col:            \n",
    "                sns.kdeplot(pretrained_data, ax=ax, fill=True, alpha=0.5, color=pretrained_color,\n",
    "                            label=f'vs {y_pretrained}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "            else:\n",
    "                ax.axvline(x=1, color=pretrained_color, lw=2, alpha=0.7)\n",
    "            sns.kdeplot(finetuned_data, ax=ax, fill=True, alpha=0.5, color=finetuned_color,\n",
    "                        label=f'vs {y_finetuned}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "\n",
    "            ax.set_xlim(global_min, global_max)\n",
    "            ax.grid(alpha=0.3)\n",
    "\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], color=pretrained_color, lw=4, alpha=0.7),\n",
    "        plt.Line2D([0], [0], color=finetuned_color, lw=4, alpha=0.7)\n",
    "    ]\n",
    "    labels = ['Pretrained', 'Fine-tuned']\n",
    "    fig.legend(handles, labels, fontsize=10, frameon=True, loc='upper left')\n",
    "    plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(pretrained, finetuned, method='iqr', factor=1.5):\n",
    "    movement_distances = np.sqrt(np.sum((finetuned - pretrained)**2, axis=1))\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        Q1 = np.percentile(movement_distances, 25)\n",
    "        Q3 = np.percentile(movement_distances, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        mask = (movement_distances >= lower_bound) & (movement_distances <= upper_bound)\n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs((movement_distances - np.mean(movement_distances)) / np.std(movement_distances))\n",
    "        mask = z_scores < factor\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_task_labels():\n",
    "    \"\"\"Get class labels for each task.\"\"\"\n",
    "    return {\n",
    "        'ad_vs_hc': ('AD', 'HC'),\n",
    "        'ad_vs_mci': ('AD', 'MCI'), \n",
    "        'mci_vs_hc': ('MCI', 'HC')\n",
    "    }\n",
    "\n",
    "def get_model_colors():\n",
    "    \"\"\"Get color palette for different models.\"\"\"\n",
    "    return {\n",
    "        'age': '#E74C3C',      # Red\n",
    "        'bmi': '#3498DB',      # Blue  \n",
    "        'sex': '#2ECC71',      # Green\n",
    "        'none': '#9B59B6'      # Purple\n",
    "    }\n",
    "\n",
    "def get_modality_markers():\n",
    "    \"\"\"Get markers for different modalities.\"\"\"\n",
    "    return {'Pretrained': 'o', 'Finetuned': 's'}\n",
    "\n",
    "def get_class_colors():\n",
    "    \"\"\"Get colors for different classes.\"\"\"\n",
    "    return {'first': '#FF6B6B', 'second': '#4ECDC4'}\n",
    "\n",
    "def prepare_data(pcas, remove_outliers=False):\n",
    "    pretrained = pcas['pretrained']\n",
    "    finetuned = pcas['finetuned']\n",
    "    n_removed = 0\n",
    "    \n",
    "    if remove_outliers:\n",
    "        outlier_mask = detect_outliers(pretrained, finetuned)\n",
    "        pretrained = pretrained[outlier_mask]\n",
    "        finetuned = finetuned[outlier_mask]\n",
    "        n_removed = np.sum(~outlier_mask)\n",
    "    \n",
    "    return pretrained, finetuned, n_removed\n",
    "\n",
    "def plot_pca(tasks_pcas, model_name, save_path=None, remove_outliers=False):\n",
    "    task_labels = get_task_labels()\n",
    "    markers = get_modality_markers()\n",
    "    class_colors = get_class_colors()\n",
    "    \n",
    "    n_tasks = len(tasks_pcas)\n",
    "    fig, axes = plt.subplots(2, n_tasks, figsize=(5*n_tasks, 10))\n",
    "    if n_tasks == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for idx, (task, models) in enumerate(tasks_pcas.items()):\n",
    "        if model_name not in models:\n",
    "            print(f\"Warning: Model '{model_name}' not found in task '{task}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Prepare data\n",
    "        pretrained, finetuned, n_removed = prepare_data(models[model_name], remove_outliers)\n",
    "        if n_removed > 0:\n",
    "            print(f\"Task {task}: Removed {n_removed} outliers from {model_name} model\")\n",
    "        \n",
    "        # Split data by class (first half vs second half)\n",
    "        n_samples = len(pretrained)\n",
    "        split_idx = n_samples // 2\n",
    "        class1_label, class2_label = task_labels.get(task, ('Class1', 'Class2'))\n",
    "        \n",
    "        pretrained_class1 = pretrained[:split_idx]\n",
    "        pretrained_class2 = pretrained[split_idx:]\n",
    "        finetuned_class1 = finetuned[:split_idx]\n",
    "        finetuned_class2 = finetuned[split_idx:]\n",
    "        \n",
    "        # Top row: Scatter plots comparing both conditions with class discrimination\n",
    "        ax_top = axes[0, idx]\n",
    "        \n",
    "        # Plot pretrained data with different colors for each class\n",
    "        ax_top.scatter(pretrained_class1[:, 0], pretrained_class1[:, 1], \n",
    "                      c=class_colors['first'], alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'Pretrained {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_top.scatter(pretrained_class2[:, 0], pretrained_class2[:, 1], \n",
    "                      c=class_colors['second'], alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'Pretrained {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # Plot finetuned data with different colors for each class  \n",
    "        ax_top.scatter(finetuned_class1[:, 0], finetuned_class1[:, 1], \n",
    "                      c=class_colors['first'], alpha=0.6, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'Finetuned {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_top.scatter(finetuned_class2[:, 0], finetuned_class2[:, 1], \n",
    "                      c=class_colors['second'], alpha=0.6, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'Finetuned {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        ax_top.set_xlabel('PC1')\n",
    "        ax_top.set_ylabel('PC2')\n",
    "        ax_top.set_title(f'{task.upper()}: {model_name.upper()} PCA Comparison')\n",
    "        ax_top.legend()\n",
    "        ax_top.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Bottom row: Difference visualization (arrows showing movement)\n",
    "        ax_bottom = axes[1, idx]\n",
    "        \n",
    "        # Calculate movement vectors for both classes\n",
    "        movement_vectors_class1 = finetuned_class1 - pretrained_class1\n",
    "        movement_vectors_class2 = finetuned_class2 - pretrained_class2\n",
    "        \n",
    "        # Plot arrows showing the movement from pretrained to finetuned for each class\n",
    "        for i in range(len(pretrained_class1)):\n",
    "            ax_bottom.arrow(pretrained_class1[i, 0], pretrained_class1[i, 1],\n",
    "                           movement_vectors_class1[i, 0], movement_vectors_class1[i, 1],\n",
    "                           head_width=0.02, head_length=0.02, \n",
    "                           fc=class_colors['first'], ec=class_colors['first'], alpha=0.3, length_includes_head=True)\n",
    "        \n",
    "        for i in range(len(pretrained_class2)):\n",
    "            ax_bottom.arrow(pretrained_class2[i, 0], pretrained_class2[i, 1],\n",
    "                           movement_vectors_class2[i, 0], movement_vectors_class2[i, 1],\n",
    "                           head_width=0.02, head_length=0.02, \n",
    "                           fc=class_colors['second'], ec=class_colors['second'], alpha=0.3, length_includes_head=True)\n",
    "        \n",
    "        # Plot starting (pretrained) and ending (finetuned) points with class discrimination\n",
    "        ax_bottom.scatter(pretrained_class1[:, 0], pretrained_class1[:, 1], \n",
    "                         c=class_colors['first'], alpha=0.8, s=40, marker=markers['Pretrained'],\n",
    "                         label=f'Pretrained {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(pretrained_class2[:, 0], pretrained_class2[:, 1], \n",
    "                         c=class_colors['second'], alpha=0.8, s=40, marker=markers['Pretrained'],\n",
    "                         label=f'Pretrained {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(finetuned_class1[:, 0], finetuned_class1[:, 1], \n",
    "                         c=class_colors['first'], alpha=0.8, s=40, marker=markers['Finetuned'],\n",
    "                         label=f'Finetuned {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(finetuned_class2[:, 0], finetuned_class2[:, 1], \n",
    "                         c=class_colors['second'], alpha=0.8, s=40, marker=markers['Finetuned'],\n",
    "                         label=f'Finetuned {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        ax_bottom.set_xlabel('PC1')\n",
    "        ax_bottom.set_ylabel('PC2')\n",
    "        ax_bottom.set_title(f'{task.upper()}: {model_name.upper()} Movement Vectors')\n",
    "        ax_bottom.legend()\n",
    "        ax_bottom.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_pca_models(tasks_pcas, task_name, model_names='all', save_path=None, remove_outliers=False):\n",
    "    if task_name not in tasks_pcas:\n",
    "        print(f\"Warning: Task '{task_name}' not found. Available tasks: {list(tasks_pcas.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    model_colors = get_model_colors()\n",
    "    markers = get_modality_markers()\n",
    "    \n",
    "    models = tasks_pcas[task_name]\n",
    "    if model_names == 'all':\n",
    "        available_models = list(models.keys())\n",
    "    else:\n",
    "        available_models = [model_names] if isinstance(model_names, str) else list(model_names)\n",
    "    # Create single plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        if model_name not in model_colors:\n",
    "            print(f\"Warning: No color defined for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Get model color\n",
    "        base_color = model_colors[model_name]\n",
    "        \n",
    "        # Handle the 'none' model which only has finetuned data\n",
    "        if model_name == 'none':\n",
    "            # Only plot finetuned data for 'none' model\n",
    "            if 'finetuned' in models[model_name]:\n",
    "                finetuned_data = models[model_name]['finetuned']\n",
    "                \n",
    "                # Apply outlier removal if requested (compare with itself as baseline)\n",
    "                if remove_outliers:\n",
    "                    # For 'none' model, we can't use movement distance, so use position-based outliers\n",
    "                    distances_from_center = np.sqrt(np.sum((finetuned_data - np.mean(finetuned_data, axis=0))**2, axis=1))\n",
    "                    if len(distances_from_center) > 0:\n",
    "                        Q1 = np.percentile(distances_from_center, 25)\n",
    "                        Q3 = np.percentile(distances_from_center, 75)\n",
    "                        IQR = Q3 - Q1\n",
    "                        upper_bound = Q3 + 1.5 * IQR\n",
    "                        outlier_mask = distances_from_center <= upper_bound\n",
    "                        finetuned_data = finetuned_data[outlier_mask]\n",
    "                        n_removed = np.sum(~outlier_mask)\n",
    "                        if n_removed > 0:\n",
    "                            print(f\"Model {model_name}: Removed {n_removed} outliers\")\n",
    "                \n",
    "                # Plot only finetuned data\n",
    "                ax.scatter(finetuned_data[:, 0], finetuned_data[:, 1], \n",
    "                          c=base_color, alpha=0.8, s=30, marker=markers['Finetuned'],\n",
    "                          label=f'{model_name.upper()} (No Pretraining)', edgecolors='white', linewidth=0.5)\n",
    "        else:\n",
    "            # Handle regular models with both pretrained and finetuned data\n",
    "            # Prepare data\n",
    "            pretrained, finetuned, n_removed = prepare_data(models[model_name], remove_outliers)\n",
    "            if n_removed > 0:\n",
    "                print(f\"Model {model_name}: Removed {n_removed} outliers\")\n",
    "            \n",
    "            # Plot pretrained data\n",
    "            ax.scatter(pretrained[:, 0], pretrained[:, 1], \n",
    "                      c=base_color, alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'{model_name.upper()} Pretrained', edgecolors='white', linewidth=0.5)\n",
    "            \n",
    "            # Plot finetuned data\n",
    "            ax.scatter(finetuned[:, 0], finetuned[:, 1], \n",
    "                      c=base_color, alpha=0.8, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'{model_name.upper()} Finetuned', edgecolors='white', linewidth=0.5)\n",
    "            \n",
    "            # Plot movement arrows (commented out to reduce clutter)\n",
    "            # movement_vectors = finetuned - pretrained\n",
    "            # for i in range(len(pretrained)):\n",
    "            #     ax.arrow(pretrained[i, 0], pretrained[i, 1],\n",
    "            #             movement_vectors[i, 0], movement_vectors[i, 1],\n",
    "            #             head_width=0.02, head_length=0.02, \n",
    "            #             fc=base_color, ec=base_color, alpha=0.2, length_includes_head=True)\n",
    "    \n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title(f'{task_name.upper()}: All Models Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_all_pcas(tasks_pcas, **kwargs):\n",
    "    # Get all available models from the first task\n",
    "    first_task = list(tasks_pcas.keys())[0]\n",
    "    available_models = list(tasks_pcas[first_task].keys())\n",
    "    \n",
    "    print(f\"Available models: {available_models}\")\n",
    "    \n",
    "    for model in available_models:\n",
    "        print(f\"\\nPlotting model: {model.upper()}\")\n",
    "        try:\n",
    "            plot_pca(tasks_pcas, model, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting model '{model}': {e}\")\n",
    "\n",
    "\n",
    "def plot_all_tasks_pcas(tasks_pcas, **kwargs):\n",
    "    available_tasks = list(tasks_pcas.keys())\n",
    "    \n",
    "    print(f\"Available tasks: {available_tasks}\")\n",
    "    \n",
    "    for task in available_tasks:\n",
    "        print(f\"\\nPlotting models comparison for task: {task.upper()}\")\n",
    "        try:\n",
    "            plot_pca_models(tasks_pcas, task, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting task '{task}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:03:21.316871Z",
     "start_time": "2025-06-23T15:03:18.497169Z"
    }
   },
   "outputs": [],
   "source": [
    "from pretrain_exp.rsa import compare_models, plot_maps, load_task_rdms\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path('pretrain_exp')\n",
    "rdms_file = 'rdms.pkl'\n",
    "results_path = base_path / 'results'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "models = ['age', 'sex', 'bmi', 'none']\n",
    "layers = ['conv0', 'conv1', 'conv2', 'conv3', 'conv4', 'conv5']\n",
    "ad_vs_hc_rdms, _ = load_task_rdms(results_path, 'ad_vs_hc')\n",
    "ad_vs_mci_rdms, _ = load_task_rdms(results_path, 'ad_vs_mci')\n",
    "mci_vs_hc_rdms, _ = load_task_rdms(results_path, 'mci_vs_hc')\n",
    "all_aucs = {task: load_aucs(results_path, task, 'aucs.csv') for task in tasks}\n",
    "auc_data = prepare_violin_data(all_aucs, 'AUC_data')\n",
    "prc_data = prepare_violin_data(all_aucs, 'PRC_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "random_state = 42\n",
    "comparisons_dict = compare_models(tasks, models, layers, results_path, n_iters, random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ft_rdms = plot_maps(ad_vs_hc_rdms['age']['tl'], 'Age finetuned', ['AD', 'HC'], layers=layers + ['fc6'])\n",
    "age_ft_rdms = plot_maps(ad_vs_mci_rdms['age']['tl'], 'Age finetuned', ['AD', 'MCI'], layers=layers + ['fc6'])\n",
    "age_ft_rdms = plot_maps(mci_vs_hc_rdms['age']['tl'], 'Age finetuned', ['MCI', 'HC'], layers=layers + ['fc6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean\n",
    "first_task = list(comparisons_dict.keys())[0]\n",
    "model_keys = list(comparisons_dict[first_task].keys())\n",
    "\n",
    "# compute mean distribution across tasks\n",
    "distance_comparison = {}\n",
    "for model in model_keys:\n",
    "    distance_comparison[model] = {}\n",
    "    for comparison in comparisons_dict[first_task][model].keys():\n",
    "        distance_comparison[model][comparison] = {}\n",
    "        for layer in comparisons_dict[first_task][model][comparison].keys():\n",
    "            # Stack the arrays from all tasks and compute element-wise mean\n",
    "            stacked = array([comparisons_dict[task][model][comparison][layer] \n",
    "                           for task in comparisons_dict.keys()])\n",
    "            distance_comparison[model][comparison][layer] = list(1 - mean(stacked, axis=0))\n",
    "\n",
    "fig = plot_model_comparisons(distance_comparison, model_type='pretrained', legend=False,\n",
    "                             colors=['#518D8C', '#957B81', '#99965D'], fig_size=(6, 5))\n",
    "fig.savefig('pretrained_comparisons.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_comparisons(comparisons_dict['mci_vs_hc'], model_type='tl', layers=['conv0', 'conv1'], legend=False, \n",
    "                             x_label=None, title=None, fig_size=(4, 5))\n",
    "# fig.savefig('mci_vs_hc_voxel_rep.png', dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean, abs, std\n",
    "layer = 'conv5'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "representational_shifts = {}\n",
    "for task in tasks:\n",
    "    print(f'Task: {task}')\n",
    "    for model in comparisons_dict[task]:\n",
    "        if model.endswith('_tl'):\n",
    "            continue\n",
    "        model_name = model.split('_')[0]\n",
    "        if not model_name in representational_shifts:\n",
    "            representational_shifts[model_name] = {}\n",
    "        finetuned_model = model_name + '_tl'\n",
    "        comparison_with_self = array(comparisons_dict[task][model][model][layer])\n",
    "        comparison_with_finetuned = array(comparisons_dict[task][model][finetuned_model][layer])\n",
    "        representational_shift = abs(comparison_with_self - comparison_with_finetuned)\n",
    "        representational_shifts[model_name][task] = representational_shift\n",
    "        print(f'Model: {model_name}, Representational Shift: {mean(representational_shift):.6f} Â± {std(representational_shift):.6f}')\n",
    "\n",
    "fig = plot_representational_shifts(representational_shifts)\n",
    "fig.patch.set_alpha(0)\n",
    "fig.savefig('representational_shifts.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_rsa_histogram_grid(comparisons_dict, layer='conv5', tasks=['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc'], only_diagonal=True)\n",
    "fig.patch.set_alpha(0)\n",
    "fig.savefig('rsa_histogram_grid.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, task = 'conv5', 'ad_vs_hc'\n",
    "fig = plot_rsa_histogram_grid(comparisons_dict, layer, task)\n",
    "# fig.savefig(base_path / 'results' / f'rsa_histogram_{task}_{layer}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Convolutional layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "results_path = Path('pretrain_exp') / 'results'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "tasks_pcas = {}\n",
    "for task in tasks:\n",
    "    with open(results_path / task / f'conv5_pcas.pkl', 'rb') as f:\n",
    "        tasks_pcas[task] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_plot = 'age' \n",
    "figure = plot_pca(tasks_pcas, model_to_plot, save_path=f\"pca_{model_to_plot}.png\", remove_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_plot = 'mci_vs_hc'\n",
    "figure = plot_pca_models(tasks_pcas, task_to_plot,\n",
    "                         model_names='all',\n",
    "                         save_path=None, \n",
    "                         remove_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig_auc, axes_auc = plt.subplots(1, 3, figsize=(11, 4))\n",
    "colors = sns.color_palette('deep', n_colors=4)\n",
    "\n",
    "axes_auc_2d = axes_auc.reshape(1, -1)\n",
    "plot_violin_data(auc_data, tasks, 'ROC-AUC', 0, axes_auc_2d, colors, fig_auc, add_legend=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pretrain_rocauc.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_prc, axes_prc = plt.subplots(1, 3, figsize=(11, 4))\n",
    "colors = sns.color_palette('deep', n_colors=4)\n",
    "\n",
    "axes_prc_2d = axes_prc.reshape(1, -1)\n",
    "plot_violin_data(prc_data, tasks, 'PRC-AUC', 0, axes_prc_2d, colors, fig_prc, add_legend=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pretrain_prcauc.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
